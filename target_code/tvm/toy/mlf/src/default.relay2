#[version = "0.0.5"]
def @main(%input_1: Tensor[(1, 640), int8] /* ty=Tensor[(1, 640), int8] span=input_1:0:0 */, %v_param_1: Tensor[(128, 640), int8] /* ty=Tensor[(128, 640), int8] span=functional_1/dense/MatMul:0:0 */, %v_param_2: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_3: Tensor[(128, 128), int8] /* ty=Tensor[(128, 128), int8] span=functional_1/dense_1/MatMul:0:0 */, %v_param_4: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_1/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_5: Tensor[(128, 128), int8] /* ty=Tensor[(128, 128), int8] span=functional_1/dense_2/MatMul:0:0 */, %v_param_6: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_2/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_7: Tensor[(128, 128), int8] /* ty=Tensor[(128, 128), int8] span=functional_1/dense_3/MatMul:0:0 */, %v_param_8: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_3/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_9: Tensor[(8, 128), int8] /* ty=Tensor[(8, 128), int8] span=functional_1/dense_4/MatMul:0:0 */, %v_param_10: Tensor[(8), int32] /* ty=Tensor[(8), int32] span=functional_1/dense_4/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_11: Tensor[(128, 8), int8] /* ty=Tensor[(128, 8), int8] span=functional_1/dense_5/MatMul:0:0 */, %v_param_12: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_5/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_13: Tensor[(128, 128), int8] /* ty=Tensor[(128, 128), int8] span=functional_1/dense_6/MatMul:0:0 */, %v_param_14: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_6/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_15: Tensor[(128, 128), int8] /* ty=Tensor[(128, 128), int8] span=functional_1/dense_7/MatMul:0:0 */, %v_param_16: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_7/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_17: Tensor[(128, 128), int8] /* ty=Tensor[(128, 128), int8] span=functional_1/dense_8/MatMul:0:0 */, %v_param_18: Tensor[(128), int32] /* ty=Tensor[(128), int32] span=functional_1/dense_8/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_19: Tensor[(640, 128), int8] /* ty=Tensor[(640, 128), int8] span=functional_1/dense_9/MatMul:0:0 */, %v_param_20: Tensor[(640), int32] /* ty=Tensor[(640), int32] span=functional_1/dense_9/BiasAdd/ReadVariableOp/resource:0:0 */, output_tensor_names=["Identity"]) -> Tensor[(1, 640), int8] {
  %0 = reshape(%input_1, newshape=[-1, 640]) /* ty=Tensor[(1, 640), int8] span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */;
  %1 = qnn.dense(%0, %v_param_1, 89 /* ty=int32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, 0.391015f /* ty=float32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, 0.000376875f /* ty=float32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */;
  %2 = nn.bias_add(%1, %v_param_2) /* ty=Tensor[(1, 128), int32] span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */;
  %3 = qnn.requantize(%2, 0.000147364f /* ty=float32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, 0.0494591f /* ty=float32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */;
  %4 = clip(%3, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation/Relu;functional_1/dense/BiasAdd:0:0 */;
  %5 = reshape(%4, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */;
  %6 = qnn.dense(%5, %v_param_3, -128 /* ty=int32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, 0.0494591f /* ty=float32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, 0.0150283f /* ty=float32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */;
  %7 = nn.bias_add(%6, %v_param_4) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */;
  %8 = qnn.requantize(%7, 0.000743288f /* ty=float32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, 0.0354057f /* ty=float32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */;
  %9 = clip(%8, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_1/Relu;functional_1/dense_1/BiasAdd:0:0 */;
  %10 = reshape(%9, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */;
  %11 = qnn.dense(%10, %v_param_5, -128 /* ty=int32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, 0.0354057f /* ty=float32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, 0.0535004f /* ty=float32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */;
  %12 = nn.bias_add(%11, %v_param_6) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */;
  %13 = qnn.requantize(%12, 0.00189422f /* ty=float32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, 0.0137307f /* ty=float32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */;
  %14 = clip(%13, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_2/Relu;functional_1/dense_2/BiasAdd:0:0 */;
  %15 = reshape(%14, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */;
  %16 = qnn.dense(%15, %v_param_7, -128 /* ty=int32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, 0.0137307f /* ty=float32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, 0.0720354f /* ty=float32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */;
  %17 = nn.bias_add(%16, %v_param_8) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */;
  %18 = qnn.requantize(%17, 0.0009891f /* ty=float32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, 0.0236038f /* ty=float32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */;
  %19 = clip(%18, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_3/Relu;functional_1/dense_3/BiasAdd:0:0 */;
  %20 = reshape(%19, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */;
  %21 = qnn.dense(%20, %v_param_9, -128 /* ty=int32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, 0.0236038f /* ty=float32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, 0.00834463f /* ty=float32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, units=8, out_dtype="int32") /* ty=Tensor[(1, 8), int32] span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */;
  %22 = nn.bias_add(%21, %v_param_10) /* ty=Tensor[(1, 8), int32] span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */;
  %23 = qnn.requantize(%22, 0.000196965f /* ty=float32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, 0.0249295f /* ty=float32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 8), int8] span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */;
  %24 = clip(%23, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 8), int8] span=functional_1/activation_4/Relu;functional_1/dense_4/BiasAdd:0:0 */;
  %25 = reshape(%24, newshape=[-1, 8]) /* ty=Tensor[(1, 8), int8] span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */;
  %26 = qnn.dense(%25, %v_param_11, -128 /* ty=int32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, 0.0249295f /* ty=float32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, 0.0267345f /* ty=float32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */;
  %27 = nn.bias_add(%26, %v_param_12) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */;
  %28 = qnn.requantize(%27, 0.000666477f /* ty=float32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, 0.0317562f /* ty=float32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */;
  %29 = clip(%28, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_5/Relu;functional_1/dense_5/BiasAdd:0:0 */;
  %30 = reshape(%29, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */;
  %31 = qnn.dense(%30, %v_param_13, -128 /* ty=int32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, 0.0317562f /* ty=float32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, 0.0193354f /* ty=float32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */;
  %32 = nn.bias_add(%31, %v_param_14) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */;
  %33 = qnn.requantize(%32, 0.000614019f /* ty=float32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, 0.0320712f /* ty=float32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */;
  %34 = clip(%33, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_6/Relu;functional_1/dense_6/BiasAdd:0:0 */;
  %35 = reshape(%34, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */;
  %36 = qnn.dense(%35, %v_param_15, -128 /* ty=int32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, 0.0320712f /* ty=float32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, 0.0128027f /* ty=float32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */;
  %37 = nn.bias_add(%36, %v_param_16) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */;
  %38 = qnn.requantize(%37, 0.000410599f /* ty=float32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, 0.028296f /* ty=float32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */;
  %39 = clip(%38, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_7/Relu;functional_1/dense_7/BiasAdd:0:0 */;
  %40 = reshape(%39, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */;
  %41 = qnn.dense(%40, %v_param_17, -128 /* ty=int32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, 0.028296f /* ty=float32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, 0.00704988f /* ty=float32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, units=128, out_dtype="int32") /* ty=Tensor[(1, 128), int32] span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */;
  %42 = nn.bias_add(%41, %v_param_18) /* ty=Tensor[(1, 128), int32] span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */;
  %43 = qnn.requantize(%42, 0.000199483f /* ty=float32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, 0 /* ty=int32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, 0.0247909f /* ty=float32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, -128 /* ty=int32 span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 128), int8] span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */;
  %44 = clip(%43, a_min=-128f, a_max=127f) /* ty=Tensor[(1, 128), int8] span=functional_1/activation_8/Relu;functional_1/dense_8/BiasAdd:0:0 */;
  %45 = reshape(%44, newshape=[-1, 128]) /* ty=Tensor[(1, 128), int8] span=Identity:0:0 */;
  %46 = qnn.dense(%45, %v_param_19, -128 /* ty=int32 span=Identity:0:0 */, 0 /* ty=int32 span=Identity:0:0 */, 0.0247909f /* ty=float32 span=Identity:0:0 */, 0.0195567f /* ty=float32 span=Identity:0:0 */, units=640, out_dtype="int32") /* ty=Tensor[(1, 640), int32] span=Identity:0:0 */;
  %47 = nn.bias_add(%46, %v_param_20) /* ty=Tensor[(1, 640), int32] span=Identity:0:0 */;
  qnn.requantize(%47, 0.000484828f /* ty=float32 span=Identity:0:0 */, 0 /* ty=int32 span=Identity:0:0 */, 0.364498f /* ty=float32 span=Identity:0:0 */, 96 /* ty=int32 span=Identity:0:0 */, rounding="UPWARD", compute_dtype="int64", out_dtype="int8") /* ty=Tensor[(1, 640), int8] span=Identity:0:0 */
}
